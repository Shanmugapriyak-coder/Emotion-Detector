{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf944f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c915437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), \n",
    "    transforms.Resize((48,48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "img_dataset = ImageFolder(r\"C:\\Users\\MY Laptop\\Desktop\\guvi_class\\emotion detection app\\train\",transform=transformation)\n",
    "dataloader = DataLoader(img_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b97da49",
   "metadata": {},
   "outputs": [],
   "source": [
    "img,label = img_dataset[0]\n",
    "in_chan , height,width = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc11b522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_chan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd48e927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_2684\\1720516324.py:35: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  nn.init.uniform(m.bias,-0.1,0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: Loss--> 1.9948209524154663\n",
      "Train Accuracy: 0.36288271970462227\n",
      "Train Precision: 0.36288271970462227\n",
      "Train Recall: 0.36288271970462227\n",
      "Train F1 Score: 0.36288271970462227\n",
      "2/10: Loss--> 1.443604588508606\n",
      "Train Accuracy: 0.40205162144275314\n",
      "Train Precision: 0.40205162144275314\n",
      "Train Recall: 0.40205162144275314\n",
      "Train F1 Score: 0.40205162144275314\n",
      "3/10: Loss--> 1.024012565612793\n",
      "Train Accuracy: 0.42951687624090007\n",
      "Train Precision: 0.42951687624090007\n",
      "Train Recall: 0.42951687624090007\n",
      "Train F1 Score: 0.42951687624090007\n",
      "4/10: Loss--> 1.2650760412216187\n",
      "Train Accuracy: 0.45005050680971126\n",
      "Train Precision: 0.45005050680971126\n",
      "Train Recall: 0.45005050680971126\n",
      "Train F1 Score: 0.45005050680971126\n",
      "5/10: Loss--> 1.3955291509628296\n",
      "Train Accuracy: 0.46662719007976594\n",
      "Train Precision: 0.46662719007976594\n",
      "Train Recall: 0.46662719007976594\n",
      "Train F1 Score: 0.46662719007976594\n",
      "6/10: Loss--> 2.094463586807251\n",
      "Train Accuracy: 0.48223553589466717\n",
      "Train Precision: 0.48223553589466717\n",
      "Train Recall: 0.48223553589466717\n",
      "Train F1 Score: 0.48223553589466717\n",
      "7/10: Loss--> 1.3722710609436035\n",
      "Train Accuracy: 0.49679294198434537\n",
      "Train Precision: 0.49679294198434537\n",
      "Train Recall: 0.49679294198434537\n",
      "Train F1 Score: 0.49679294198434537\n",
      "8/10: Loss--> 0.7886896133422852\n",
      "Train Accuracy: 0.5114728830680274\n",
      "Train Precision: 0.5114728830680274\n",
      "Train Recall: 0.5114728830680274\n",
      "Train F1 Score: 0.5114728830680274\n",
      "9/10: Loss--> 0.7536090016365051\n",
      "Train Accuracy: 0.5259287641119123\n",
      "Train Precision: 0.5259287641119123\n",
      "Train Recall: 0.5259287641119123\n",
      "Train F1 Score: 0.5259287641119123\n",
      "10/10: Loss--> 1.2806460857391357\n",
      "Train Accuracy: 0.5401651050193319\n",
      "Train Precision: 0.5401651050193319\n",
      "Train Recall: 0.5401651050193319\n",
      "Train F1 Score: 0.5401651050193319\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "           nn.Conv2d(in_chan,32,kernel_size=3,stride=1),#[32,46,46]\n",
    "           nn.Conv2d(32,64,kernel_size=3,stride=1),#[64,44,44]\n",
    "           nn.MaxPool2d(kernel_size=2,stride=2)#[64,22,22]\n",
    "\n",
    "        )\n",
    "        self.nn = nn.Sequential(\n",
    "           nn.Flatten(),\n",
    "           nn.Linear(64*22*22,128),\n",
    "           nn.Linear(128,64),\n",
    "           nn.Linear(64,7)\n",
    "\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        X = self.cnn(X)\n",
    "        X = self.nn(X)\n",
    "        return X\n",
    "model = CNN()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)\n",
    "        nn.init.uniform(m.bias,-0.1,0.1)\n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "num_epoch = 10\n",
    "prediction = []\n",
    "actual = []\n",
    "\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    for x,y in dataloader:\n",
    "       optimizer.zero_grad()\n",
    "       output = model(x)\n",
    "       loss = criterion(output,y)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       actual.extend(y.numpy())\n",
    "       pred = torch.argmax(output,dim=1)\n",
    "       prediction.extend(pred.numpy())\n",
    "    print(f\"{epoch}/{num_epoch}: Loss--> {loss.item()}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(actual,prediction)}\")\n",
    "    print(f\"Train Precision: {precision_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train Recall: {recall_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train F1 Score: {f1_score(actual,prediction,average='micro')}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8187114d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_5760\\4280182611.py:50: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  nn.init.uniform(m.bias,-0.1,0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10: Loss--> 1.5355958938598633\n",
      "Train Accuracy: 0.343550802884113\n",
      "Train Precision: 0.343550802884113\n",
      "Train Recall: 0.343550802884113\n",
      "Train F1 Score: 0.343550802884113\n",
      "2/10: Loss--> 0.9044612646102905\n",
      "Train Accuracy: 0.40017067818454144\n",
      "Train Precision: 0.40017067818454144\n",
      "Train Recall: 0.40017067818454144\n",
      "Train F1 Score: 0.40017067818454144\n",
      "3/10: Loss--> 1.4260250329971313\n",
      "Train Accuracy: 0.4366574941655927\n",
      "Train Precision: 0.4366574941655927\n",
      "Train Recall: 0.4366574941655927\n",
      "Train F1 Score: 0.4366574941655927\n",
      "4/10: Loss--> 1.4188224077224731\n",
      "Train Accuracy: 0.46461910899021214\n",
      "Train Precision: 0.46461910899021214\n",
      "Train Recall: 0.46461910899021214\n",
      "Train F1 Score: 0.46461910899021214\n",
      "5/10: Loss--> 0.44716304540634155\n",
      "Train Accuracy: 0.49035494095928106\n",
      "Train Precision: 0.49035494095928106\n",
      "Train Recall: 0.49035494095928106\n",
      "Train F1 Score: 0.49035494095928106\n",
      "6/10: Loss--> 0.9662763476371765\n",
      "Train Accuracy: 0.5139271076433639\n",
      "Train Precision: 0.5139271076433639\n",
      "Train Recall: 0.5139271076433639\n",
      "Train F1 Score: 0.5139271076433639\n",
      "7/10: Loss--> 0.5817156434059143\n",
      "Train Accuracy: 0.5363823191333729\n",
      "Train Precision: 0.5363823191333729\n",
      "Train Recall: 0.5363823191333729\n",
      "Train F1 Score: 0.5363823191333729\n",
      "8/10: Loss--> 0.4325961470603943\n",
      "Train Accuracy: 0.558644501724198\n",
      "Train Precision: 0.558644501724198\n",
      "Train Recall: 0.558644501724198\n",
      "Train F1 Score: 0.558644501724198\n",
      "9/10: Loss--> 0.6183934211730957\n",
      "Train Accuracy: 0.5798491375139813\n",
      "Train Precision: 0.5798491375139813\n",
      "Train Recall: 0.5798491375139813\n",
      "Train F1 Score: 0.5798491375139813\n",
      "10/10: Loss--> 0.058391131460666656\n",
      "Train Accuracy: 0.6005190010101362\n",
      "Train Precision: 0.6005190010101362\n",
      "Train Recall: 0.6005190010101362\n",
      "Train F1 Score: 0.6005190010101362\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # [32, 48, 48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),                           # [32, 24, 24]\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # [64, 24, 24]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),                           # [64, 12, 12]\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # [128, 12, 12]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2)                            # [128, 6, 6]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 6 * 6, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 7)  # 7 output classes for emotions\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)\n",
    "        nn.init.uniform(m.bias,-0.1,0.1)\n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "num_epoch = 10\n",
    "prediction = []\n",
    "actual = []\n",
    "\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    for x,y in dataloader:\n",
    "       optimizer.zero_grad()\n",
    "       output = model(x)\n",
    "       loss = criterion(output,y)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       actual.extend(y.numpy())\n",
    "       pred = torch.argmax(output,dim=1)\n",
    "       prediction.extend(pred.numpy())\n",
    "    print(f\"{epoch}/{num_epoch}: Loss--> {loss.item()}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(actual,prediction)}\")\n",
    "    print(f\"Train Precision: {precision_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train Recall: {recall_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train F1 Score: {f1_score(actual,prediction,average='micro')}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80386d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY Laptop\\AppData\\Local\\Temp\\ipykernel_8364\\3961457293.py:50: FutureWarning: `nn.init.uniform` is now deprecated in favor of `nn.init.uniform_`.\n",
      "  nn.init.uniform(m.bias,-0.1,0.1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/20: Loss--> 1.9266659021377563\n",
      "Train Accuracy: 0.34358563516667245\n",
      "Train Precision: 0.34358563516667245\n",
      "Train Recall: 0.34358563516667245\n",
      "Train F1 Score: 0.34358563516667245\n",
      "2/20: Loss--> 0.6315154433250427\n",
      "Train Accuracy: 0.4033404158974538\n",
      "Train Precision: 0.4033404158974538\n",
      "Train Recall: 0.4033404158974538\n",
      "Train F1 Score: 0.4033404158974538\n",
      "3/20: Loss--> 0.9472552537918091\n",
      "Train Accuracy: 0.4403264945951908\n",
      "Train Precision: 0.4403264945951908\n",
      "Train Recall: 0.4403264945951908\n",
      "Train F1 Score: 0.4403264945951908\n",
      "4/20: Loss--> 1.9053614139556885\n",
      "Train Accuracy: 0.46911247344038454\n",
      "Train Precision: 0.46911247344038454\n",
      "Train Recall: 0.46911247344038454\n",
      "Train F1 Score: 0.46911247344038454\n",
      "5/20: Loss--> 0.7601266503334045\n",
      "Train Accuracy: 0.4931415235640392\n",
      "Train Precision: 0.4931415235640392\n",
      "Train Recall: 0.4931415235640392\n",
      "Train F1 Score: 0.4931415235640392\n",
      "6/20: Loss--> 1.3697712421417236\n",
      "Train Accuracy: 0.5161157360641843\n",
      "Train Precision: 0.5161157360641843\n",
      "Train Recall: 0.5161157360641843\n",
      "Train F1 Score: 0.5161157360641843\n",
      "7/20: Loss--> 0.8579039573669434\n",
      "Train Accuracy: 0.5383080467548753\n",
      "Train Precision: 0.5383080467548753\n",
      "Train Recall: 0.5383080467548753\n",
      "Train F1 Score: 0.5383080467548753\n",
      "8/20: Loss--> 0.4699091911315918\n",
      "Train Accuracy: 0.5602903270751333\n",
      "Train Precision: 0.5602903270751333\n",
      "Train Recall: 0.5602903270751333\n",
      "Train F1 Score: 0.5602903270751333\n",
      "9/20: Loss--> 0.2875846326351166\n",
      "Train Accuracy: 0.5814436820044817\n",
      "Train Precision: 0.5814436820044817\n",
      "Train Recall: 0.5814436820044817\n",
      "Train F1 Score: 0.5814436820044817\n",
      "10/20: Loss--> 0.26668256521224976\n",
      "Train Accuracy: 0.6016301508237835\n",
      "Train Precision: 0.6016301508237835\n",
      "Train Recall: 0.6016301508237835\n",
      "Train F1 Score: 0.6016301508237835\n",
      "11/20: Loss--> 0.32794705033302307\n",
      "Train Accuracy: 0.6210310988951834\n",
      "Train Precision: 0.6210310988951834\n",
      "Train Recall: 0.6210310988951834\n",
      "Train F1 Score: 0.6210310988951834\n",
      "12/20: Loss--> 0.4894840121269226\n",
      "Train Accuracy: 0.6388676024939914\n",
      "Train Precision: 0.6388676024939914\n",
      "Train Recall: 0.6388676024939914\n",
      "Train F1 Score: 0.6388676024939914\n",
      "13/20: Loss--> 0.5385453104972839\n",
      "Train Accuracy: 0.65517379969294\n",
      "Train Precision: 0.65517379969294\n",
      "Train Recall: 0.65517379969294\n",
      "Train F1 Score: 0.65517379969294\n",
      "14/20: Loss--> 0.24216409027576447\n",
      "Train Accuracy: 0.670760289207466\n",
      "Train Precision: 0.670760289207466\n",
      "Train Recall: 0.670760289207466\n",
      "Train F1 Score: 0.670760289207466\n",
      "15/20: Loss--> 0.7191147804260254\n",
      "Train Accuracy: 0.6847190776411578\n",
      "Train Precision: 0.6847190776411578\n",
      "Train Recall: 0.6847190776411578\n",
      "Train F1 Score: 0.6847190776411578\n",
      "16/20: Loss--> 0.6066232919692993\n",
      "Train Accuracy: 0.6975033961475495\n",
      "Train Precision: 0.6975033961475495\n",
      "Train Recall: 0.6975033961475495\n",
      "Train F1 Score: 0.6975033961475495\n",
      "17/20: Loss--> 0.013994568958878517\n",
      "Train Accuracy: 0.7095827707236714\n",
      "Train Precision: 0.7095827707236714\n",
      "Train Recall: 0.7095827707236714\n",
      "Train F1 Score: 0.7095827707236714\n",
      "18/20: Loss--> 0.12256475538015366\n",
      "Train Accuracy: 0.7205096349963813\n",
      "Train Precision: 0.7205096349963813\n",
      "Train Recall: 0.7205096349963813\n",
      "Train F1 Score: 0.7205096349963813\n",
      "19/20: Loss--> 0.42972618341445923\n",
      "Train Accuracy: 0.7307537889273673\n",
      "Train Precision: 0.7307537889273673\n",
      "Train Recall: 0.7307537889273673\n",
      "Train F1 Score: 0.7307537889273673\n",
      "20/20: Loss--> 0.17086395621299744\n",
      "Train Accuracy: 0.7400693162422933\n",
      "Train Precision: 0.7400693162422933\n",
      "Train Recall: 0.7400693162422933\n",
      "Train F1 Score: 0.7400693162422933\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn,optim\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),   # [32, 48, 48]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2, 2),                           # [32, 24, 24]\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # [64, 24, 24]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2, 2),                           # [64, 12, 12]\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1), # [128, 12, 12]\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2, 2)                            # [128, 6, 6]\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 6 * 6, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 7)  # 7 output classes for emotions\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = CNN()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.uniform_(m.weight,-0.1,0.1)\n",
    "        nn.init.uniform(m.bias,-0.1,0.1)\n",
    "model.apply(init_weights)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "num_epoch = 20\n",
    "prediction = []\n",
    "actual = []\n",
    "\n",
    "for epoch in range(1,num_epoch+1):\n",
    "    for x,y in dataloader:\n",
    "       optimizer.zero_grad()\n",
    "       output = model(x)\n",
    "       loss = criterion(output,y)\n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "       actual.extend(y.numpy())\n",
    "       pred = torch.argmax(output,dim=1)\n",
    "       prediction.extend(pred.numpy())\n",
    "    print(f\"{epoch}/{num_epoch}: Loss--> {loss.item()}\")\n",
    "    print(f\"Train Accuracy: {accuracy_score(actual,prediction)}\")\n",
    "    print(f\"Train Precision: {precision_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train Recall: {recall_score(actual,prediction,average='micro')}\")\n",
    "    print(f\"Train F1 Score: {f1_score(actual,prediction,average='micro')}\")\n",
    "\n",
    "torch.save(model.state_dict(), 'emotion_cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ea37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `model` is your trained CNN model\n",
    "torch.save(model.state_dict(), 'emotion_cnn_model.pth')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd711e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load('emotion_cnn_model.pth', map_location=torch.device('cpu')))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
